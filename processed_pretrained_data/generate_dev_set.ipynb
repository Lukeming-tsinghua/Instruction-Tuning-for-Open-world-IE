{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"/harddisk/data/nlp_data/kb/wikipedia/20220620/enwiki-20220620/output/\"\n",
    "sup_data_dir = \"/harddisk/data/nlp_data/kb/wikipedia/20230301/enwiki-20230301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_data_dir, \"redirect.json\")) as f:\n",
    "    train_redirect_map = json.load(f)\n",
    "with open(os.path.join(sup_data_dir, \"redirect.json\")) as f:\n",
    "    sup_redicrect_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(train_data_dir, \"title2id.json\")) as f:\n",
    "    train_title_map = json.load(f)\n",
    "with open(os.path.join(sup_data_dir, \"title2id.json\")) as f:\n",
    "    sup_title_map = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16646038, 17063901)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_title_map), len(sup_title_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_title_redirect = set(train_redirect_map[title] if title in train_redirect_map else title for title in train_title_map.keys())\n",
    "sup_title_redirect = set(sup_redicrect_map[title] if title in sup_redicrect_map else title for title in sup_title_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6545405, 6655001)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_title_redirect), len(sup_title_redirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_titles = sup_title_redirect.difference(train_title_redirect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180539\n",
      "176504\n"
     ]
    }
   ],
   "source": [
    "print(len(sub_titles))\n",
    "sub_titles = set(title for title in sub_titles if not title.startswith(\"List of\"))\n",
    "print(len(sub_titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_article_path = \"/harddisk/data/nlp_data/kb/wikipedia/20230301/enwiki-20230301/blocks.ann\"\n",
    "files = [os.path.join(sup_article_path, file_path) for file_path in os.listdir(sup_article_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2272it [07:35,  4.99it/s]\n"
     ]
    }
   ],
   "source": [
    "def init():\n",
    "    global sup_redicrect_map\n",
    "\n",
    "def run(file):\n",
    "    output_data_dir = \"/harddisk/data/nlp_data/kb/wikipedia/subset\"\n",
    "    with open(file) as f:\n",
    "        with open(os.path.join(output_data_dir, file.split(\"/\")[-1].replace(\".ann\", \"_filtered.ann\")), \"w\") as fo:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                data = json.loads(line)\n",
    "                title = data['title']\n",
    "                if title in sup_redicrect_map:\n",
    "                    title = sup_redicrect_map[title]\n",
    "                if title in sub_titles:\n",
    "                    fo.write(line)\n",
    "                line = f.readline()\n",
    "\n",
    "\n",
    "print(\"Preprocessing files...\")\n",
    "with Pool(64, initializer=init) as pool:\n",
    "    for output in tqdm(pool.imap_unordered(run, files)):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downstream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from multiprocessing.pool import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_config = {\"host\": '9.109.142.31', \"port\": 27017}\n",
    "dbname='wikidata-20230301'\n",
    "new_client = MongoClient(**mongodb_config)\n",
    "new_kg_collection = new_client[dbname]['kg']\n",
    "new_raw_collection = new_client[dbname]['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_config = {\"host\": '10.12.192.31', \"port\": 27017}\n",
    "dbname=\"wikidata\"\n",
    "old_client = MongoClient(**mongodb_config)\n",
    "old_kg_collection = old_client[dbname]['kg']\n",
    "old_raw_collection = old_client[dbname]['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus\"\n",
    "data = []\n",
    "with open(data_file) as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        data.append(json.loads(line))\n",
    "        line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mapping = json.load(open(\"/harddisk/data/nlp_data/kb/wikidata/20230301/mapping/sitelinks.enwiki.title.json\"))\n",
    "new_inverse_mapping = {value: key for key, value in new_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_mapping = json.load(open(\"/harddisk/data/nlp_data/kb/wikidata/20210520/mapping/qid2sitelinks.enwiki.title.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = set(new_mapping.keys()).difference(set(old_mapping.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 698673/698673 [05:29<00:00, 2122.37it/s]\n"
     ]
    }
   ],
   "source": [
    "new_ent_strict = []\n",
    "for new_ent in tqdm(new_ents):\n",
    "    if not old_raw_collection.find_one({\"id\": new_ent}):\n",
    "        new_ent_strict.append(new_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698673, 496627)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_ents), len(new_ent_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/evaluation_corpus/wiki_eval/new_entity_qid.json\", \"w\") as f:\n",
    "    json.dump(new_ent_strict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(record):\n",
    "    targets = json.loads(record['targets'])\n",
    "    for i, ent in enumerate(targets['entities']):\n",
    "        ent_type = 'in'\n",
    "        if ent['title'] in new_inverse_mapping:\n",
    "            qid = new_inverse_mapping[ent['title']]\n",
    "            if qid in new_ent_strict:\n",
    "                info = new_raw_collection.find_one({\"id\": qid})\n",
    "                if len(info['descriptions']) > 0:\n",
    "                    ent_type = 'ood_m'\n",
    "                else:\n",
    "                    ent_type = 'ood'\n",
    "        targets['entities'][i]['ood'] = ent_type\n",
    "    record['targets'] = json.dumps(targets)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/319298 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 319282/319298 [30:58<00:00, 160.49it/s]"
     ]
    }
   ],
   "source": [
    "def init():\n",
    "    global new_inverse_mapping\n",
    "    global new_ent_strict\n",
    "    global new_raw_collection\n",
    "\n",
    "pbar = tqdm(total=len(data))\n",
    "print(\"Preprocessing files...\")\n",
    "with Pool(64, initializer=init) as pool:\n",
    "    with open(os.path.join(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval\", \"corpus_w_oom\"), \"w\") as f:\n",
    "        for output in pool.imap_unordered(run, data):\n",
    "            f.write(json.dumps(output) + \"\\n\")\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319298/319298 [31:15<00:00, 160.49it/s]"
     ]
    }
   ],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_w_oom\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "oom_data = []\n",
    "for record in data:\n",
    "    entities = json.loads(record[\"targets\"])[\"entities\"] \n",
    "    ood_samples = [ent for ent in entities if ent[\"ood\"] != \"in\"]\n",
    "    if len(ood_samples) > 0:\n",
    "        oom_data.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2710 24393\n"
     ]
    }
   ],
   "source": [
    "dev_size = len(oom_data) // 10\n",
    "dev_oom_data = oom_data[:dev_size]\n",
    "test_oom_data = oom_data[dev_size:]\n",
    "print(len(dev_oom_data), len(test_oom_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_test\", \"w\") as f:\n",
    "    for record in test_oom_data:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev\", \"w\") as f:\n",
    "    for record in dev_oom_data:\n",
    "        f.write(json.dumps(record) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark OOO types and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_types = json.load(open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug/train_types.json\"))\n",
    "train_relations = json.load(open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug/train_relations.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev_prompt_rephrased\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [sample for sample in data if sample['aug_type'] == 'aug_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_types = sum([each['type'] if 'type' in each else [] for sample in data for each in json.loads(sample['targets'])['entities']], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(all_types).difference(set(train_types)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4c793426adf016a6deb589c78ef9b52b0d2671097f5c49eb7a518bfd664e7c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
