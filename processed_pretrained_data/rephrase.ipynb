{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_fns = {\n",
    "    \"aug_default\": lambda message: True,\n",
    "    \"aug_ent_num\": lambda message: '{number}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "    \"aug_importance\": lambda message: '{number}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "    \"aug_base_type\": lambda message: '{types}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "    \"aug_rollup_type\": lambda message: '{types}' in message and 'Please provide' not in message and 'plesae provide' not in message,\n",
    "    \"aug_ent_num_and_base_type\": lambda message: '{types}' in message and '{number}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "    \"aug_ent_num_and_rollup_type\": lambda message: '{types}' in message and '{number}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "    \"aug_description\": lambda message: '{descriptions}' in message and 'Please provide' not in message and 'please provide' not in message,\n",
    "}\n",
    "queries = {\n",
    "    \"aug_default\": \"Context: ``Extract entities.''\\n\\n Please rephrase this context.\",\n",
    "    \"aug_ent_num\": \"Context: ``Extract {number} entities.''\\n\\n {number} in the context is a placeholder for the number of entity. Please rephrase this context and keep {number} in the rephrased sentence.\",\n",
    "    \"aug_importance\": \"Context: ``Extract the most important {number} entities.''\\n\\n {number} in the context is a placeholder for the number of entity. Please rephrase this context and keep {number} in the rephrased sentence.\",\n",
    "    \"aug_base_type\": \"Context: ``Extract entities in types {types}.''\\n\\n {types} in the context is a placeholder for a list of entity types. Please rephrase this context and keep {types} in the rephrased sentence. {types} should be put after the word ``types''\",\n",
    "    \"aug_rollup_type\": \"Context: ``Extract entities in types {types}.''\\n\\n {types} in the context is a placeholder for a list of entity types. Please rephrase this context and keep {types} in the rephrased sentence. {types} should be put after the word ``types''\",\n",
    "    \"aug_ent_num_and_base_type\": \"Context: ``Extract {number} entities in types {types}.''\\n\\n {types} in the context is a placeholder for a list of entity types. {number} in the context is a placeholder for the number of entities. Please rephrase this context and keep {types} and {number} in the rephrased sentence. {types} should be put after the word ``types''\",\n",
    "    \"aug_ent_num_and_rollup_type\": \"Context: ``Extract {number} entities in types {types}.''\\n\\n {types} in the context is a placeholder for a list of entity types. {number} in the context is a placeholder for the number of entities. Please rephrase this context and keep {types} and {number} in the rephrased sentence. {types} should be put after the word ``types''\",\n",
    "    \"aug_description\": \"Context: ``Extract entities in following descriptions: {descriptions}''\\n\\n {descriptions} in the context is a placeholder for a list of entity descriptions. Please rephrase this context and keep {descriptions} in the rephrased sentence.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_chatgpt(query):\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=random.random(),\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": query},\n",
    "            ]\n",
    "        )\n",
    "        message = response['choices'][0]['message']['content'].replace('\"', '')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        message = None\n",
    "    return message\n",
    "\n",
    "\n",
    "def generation(aug_type, maximum_step=1000):\n",
    "    generated_case = set()\n",
    "    query = [queries[aug_type] for _ in range(maximum_step)]\n",
    "\n",
    "    outputs = []\n",
    "    with Pool(64) as p:\n",
    "        pbar = tqdm(total=maximum_step)\n",
    "        for output in p.imap_unordered(query_chatgpt, query):\n",
    "            outputs.append(output)\n",
    "            pbar.update(1)\n",
    "\n",
    "    for message in outputs:\n",
    "        if message:\n",
    "            message = message.replace('`', '').replace(\"'\", \"\") \n",
    "            if \":\" in message:\n",
    "                message = message.split(\":\")[1].strip()\n",
    "            if message not in generated_case and valid_fns[aug_type](message):\n",
    "                generated_case.add(message)\n",
    "\n",
    "    generated_case = list(generated_case)\n",
    "    return generated_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrased_prompts = {\n",
    "    \"aug_default\": [],\n",
    "    \"aug_ent_num\": [],\n",
    "    \"aug_importance\": [],\n",
    "    \"aug_base_type\": [],\n",
    "    \"aug_rollup_type\": [],\n",
    "    \"aug_ent_num_and_base_type\": [],\n",
    "    \"aug_ent_num_and_rollup_type\": [],\n",
    "    \"aug_description\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:11<00:00, 85.99it/s]\n",
      "100%|██████████| 1000/1000 [00:09<00:00, 106.29it/s]\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 84.76it/s]\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 85.57it/s]\n",
      "100%|██████████| 1000/1000 [00:11<00:00, 85.96it/s]\n",
      "100%|██████████| 1000/1000 [00:12<00:00, 77.89it/s]\n",
      "100%|██████████| 1000/1000 [00:12<00:00, 78.53it/s]\n",
      "100%|██████████| 1000/1000 [00:14<00:00, 67.22it/s]\n"
     ]
    }
   ],
   "source": [
    "for aug_type in rephrased_prompts:\n",
    "    rephrased_prompts[aug_type] = generation(aug_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[219, 49, 62, 50, 50, 117, 105, 108]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(rephrased_prompts[key]) for key in rephrased_prompts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/evaluation_corpus/resources/rephrased_prompts.json\", \"w\") as f:\n",
    "    json.dump(rephrased_prompts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/evaluation_corpus/resources/rephrased_prompts_prettify.json\") as f:\n",
    "    rephrased_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rephrased_prompt(sample):\n",
    "    candidates = rephrased_prompts[sample['aug_type']]\n",
    "    random.shuffle(candidates)\n",
    "    if sample['aug_type'] == 'aug_default':\n",
    "        message = candidates[0]\n",
    "    elif sample['aug_type'] in ('aug_ent_num', 'aug_importance'):\n",
    "        message = candidates[0].format(number=sample['aug_info'])\n",
    "    elif sample['aug_type'] in ('aug_base_type', 'aug_rollup_type'):\n",
    "        message = candidates[0].format(types=sample['aug_info'])\n",
    "    elif sample['aug_type'] in ('aug_ent_num_and_base_type', 'aug_ent_num_and_rollup_type'):\n",
    "        message = candidates[0].format(number=sample['aug_info'][0], types=sample['aug_info'][1])\n",
    "    elif sample['aug_type'] == 'aug_description':\n",
    "        message = candidates[0].format(descriptions=sample['aug_info'])\n",
    "    else:\n",
    "        raise ValueError(f\"aug_type {sample['aug_type']} is not implemented\")\n",
    "    \n",
    "    assert re.match(r'{.*}', message) is None\n",
    "\n",
    "    sample['original_inputs'] = f\"\\\"{sample['inputs']}\\\"\\n\\n\" + sample['prompt']\n",
    "    sample['rephrased_prompt'] = message\n",
    "    sample['rephrased_inputs'] = f\"\\\"{sample['inputs']}\\\"\\n\\n\" + message\n",
    "\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev\"\n",
    "with open(input_file_path) as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 24000/24393 [01:56<00:01, 205.31it/s]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "output_file_path = input_file_path + \"_prompt_rephrased\"\n",
    "with Pool(64) as p:\n",
    "    pbar = tqdm(total=len(data))\n",
    "    with open(output_file_path, \"w\") as f:\n",
    "        for i, sample in enumerate(p.imap_unordered(generate_rephrased_prompt, data)):\n",
    "            f.write(json.dumps(sample) + \"\\n\")\n",
    "            if (i + 1) % 1000 == 0:\n",
    "                pbar.update(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev_prompt_rephrased\") as f:\n",
    "    dev_data = [json.loads(line) for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dev_data)):\n",
    "    targets = json.loads(dev_data[i]['targets'])\n",
    "    for j in range(len(targets['entities'])):\n",
    "        del targets['entities'][j]['ood']\n",
    "    targets = json.dumps(targets)\n",
    "    dev_data[i]['targets'] = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev_processed_prompt_rephrased\", \"w\") as f:\n",
    "    for each in dev_data:\n",
    "        f.write(json.dumps(each) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = {}\n",
    "for sample in data:\n",
    "    if sample['aug_type'] == 'aug_default':\n",
    "        if sample['rephrased_prompt'] not in cnt:\n",
    "            cnt[sample['rephrased_prompt']] = 0\n",
    "        cnt[sample['rephrased_prompt']] += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4c793426adf016a6deb589c78ef9b52b0d2671097f5c49eb7a518bfd664e7c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
