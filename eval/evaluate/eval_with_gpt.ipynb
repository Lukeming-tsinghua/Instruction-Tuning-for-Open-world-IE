{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import copy\n",
    "from multiprocess import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = [json.loads(line) for line in open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_dev_processed_prompt_rephrased\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_fewshot_cases = {}\n",
    "for each in dev_data:\n",
    "    if each['aug_type'] not in collect_fewshot_cases:\n",
    "        collect_fewshot_cases[each['aug_type']] = each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_shot_prompt_templates = {}\n",
    "for key in collect_fewshot_cases:\n",
    "    one_shot_prompt = \"This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n\"\n",
    "    sample = collect_fewshot_cases[key]\n",
    "    one_shot_prompt += \"[input] \" + sample['inputs'] + \"\\n\"\n",
    "    one_shot_prompt += \"[instruction] \" + sample['rephrased_prompt'] + \"\\n\"\n",
    "    one_shot_prompt += \"[output] \" + sample['targets'] + \"\\n\\n\"\n",
    "    one_shot_prompt_templates[key] = one_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aug_default': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] The Wheelchair Rugby League World Cup is an international wheelchair rugby league tournament contested by the top national teams. The tournament was first held in 2008 as part of the Festival of World Cups held in Australia. The first winners were England who then hosted the tournament in 2013 and lost to France in the final. At the 2017 tournament the title was retained by France who were also the host nation. The 2021 tournament was held in November 2022 as part of the 2021 Rugby League World Cup with eight teams taking part. It was hosted by England who also won the tournament.\\n[instruction] Identify the objects or concepts that represent specific things or ideas.\\n[output] {\"entities\": [{\"mention\": \"2017 tournament\", \"title\": \"2017 Festival of World Cups\", \"type\": [\"Season (sports)\"]}, {\"mention\": \"wheelchair rugby league\", \"title\": \"Wheelchair rugby league\", \"type\": [\"Sport\"], \"description\": \"Version of rugby league football\"}, {\"mention\": \"2021 tournament\", \"title\": \"2021 Wheelchair Rugby League World Cup\", \"type\": [\"Season (sports)\"], \"description\": \"fourth staging of the Wheelchair Rugby League World Cup\"}, {\"mention\": \"Festival of World Cups\", \"title\": \"Festival of World Cups\"}, {\"mention\": \"England\", \"title\": \"England national wheelchair rugby league team\", \"type\": [\"Sports team\"], \"description\": \"team representing England in Wheelchair Rugby League\"}, {\"mention\": \"tournament in 2013\", \"title\": \"2013 Festival of World Cups\", \"type\": [\"Season (sports)\"]}, {\"mention\": \"2021 Rugby League World Cup\", \"title\": \"2021 Rugby League World Cup\", \"description\": \"international rugby league tournaments held in 2022\"}], \"triplets\": [{\"head\": \"England\", \"tail\": \"wheelchair rugby league\", \"relations\": [\"sport\"]}]}\\n\\n',\n",
       " 'aug_importance': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] The Wheelchair Rugby League World Cup is an international wheelchair rugby league tournament contested by the top national teams. The tournament was first held in 2008 as part of the Festival of World Cups held in Australia. The first winners were England who then hosted the tournament in 2013 and lost to France in the final. At the 2017 tournament the title was retained by France who were also the host nation. The 2021 tournament was held in November 2022 as part of the 2021 Rugby League World Cup with eight teams taking part. It was hosted by England who also won the tournament.\\n[instruction] Identify 6 entities of utmost significance.\\n[output] {\"entities\": [{\"mention\": \"2021 Rugby League World Cup\", \"title\": \"2021 Rugby League World Cup\", \"description\": \"international rugby league tournaments held in 2022\"}, {\"mention\": \"wheelchair rugby league\", \"title\": \"Wheelchair rugby league\", \"type\": [\"Sport\"], \"description\": \"Version of rugby league football\"}, {\"mention\": \"2021 tournament\", \"title\": \"2021 Wheelchair Rugby League World Cup\", \"type\": [\"Season (sports)\"], \"description\": \"fourth staging of the Wheelchair Rugby League World Cup\"}, {\"mention\": \"England\", \"title\": \"England national wheelchair rugby league team\", \"type\": [\"Sports team\"], \"description\": \"team representing England in Wheelchair Rugby League\"}, {\"mention\": \"Festival of World Cups\", \"title\": \"Festival of World Cups\"}, {\"mention\": \"tournament in 2013\", \"title\": \"2013 Festival of World Cups\", \"type\": [\"Season (sports)\"]}], \"triplets\": [{\"head\": \"England\", \"tail\": \"wheelchair rugby league\", \"relations\": [\"sport\"]}]}\\n\\n',\n",
       " 'aug_base_type': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] \"Party Time\" is a song written by Bruce Channel, and recorded by American country music artist T. G. Sheppard. It was released in June 1981 as the second single from the album \"I Love \\'Em All\". The song was Sheppard\\'s eighth number one on the country chart. The single stayed at number one for one week and spent a total of thirteen weeks on the country chart.\\n[instruction] Please parse out the entities falling under the categories of Album, Human.\\n[output] {\"entities\": [{\"mention\": \"T. G. Sheppard\", \"title\": \"T. G. Sheppard\", \"type\": [\"Human\"], \"description\": \"American country music singer-songwriter\", \"aliases\": [\"William Neal Browder\", \"Brian Stacy\"]}, {\"mention\": \"Bruce Channel\", \"title\": \"Bruce Channel\", \"type\": [\"Human\"], \"description\": \"American musician\"}, {\"mention\": \"I Love \\'Em All\", \"title\": \"I Love \\'Em All\", \"type\": [\"Album\"], \"description\": \"1981 studio album by T. G. Sheppard\"}], \"triplets\": [{\"head\": \"I Love \\'Em All\", \"tail\": \"T. G. Sheppard\", \"relations\": [\"performer\"]}]}\\n\\n',\n",
       " 'aug_ent_num': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] \"Country Girls\" is a song written by Troy Seals and Eddie Setser, and recorded by actor and American country music artist John Schneider. It was released in December 1984 as the second single from the album \"Too Good to Stop Now\". The song was Schneider\\'s second number one on the country chart. The single went to number one for one week, and spent a total of fourteen weeks on the country chart.\\n[instruction] Get 1 entities from the data.\\n[output] {\"entities\": [{\"mention\": \"Too Good to Stop Now\", \"title\": \"Too Good to Stop Now (John Schneider album)\", \"type\": [\"Album\"], \"description\": \"1984 studio album by John Schneider\"}], \"triplets\": []}\\n\\n',\n",
       " 'aug_description': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] The Ovintiv Events Centre (formerly named Encana Events Centre to June 2021), is a multipurpose arena located in Dawson Creek, British Columbia. The name change came about due to a reorganization of the former Encana Corporation, where the organization adopted the new name \"Ovintiv Inc.\" The facility has 4,500 permanent seats and can seat up to 6,500 for concerts.\\n[instruction] Please identify the entities mentioned in the set of descriptions provided in city in Peace River Regional District, British Columbia, Canada; province of Canada.\\n[output] {\"entities\": [{\"mention\": \"Dawson Creek\", \"title\": \"Dawson Creek\", \"description\": \"city in Peace River Regional District, British Columbia, Canada\", \"aliases\": [\"City of Dawson Creek\", \"Dawson Creek, British Columbia\", \"Dawson Creek, BC\"]}, {\"mention\": \"British Columbia\", \"title\": \"British Columbia\", \"type\": [\"Provinces of Canada\"], \"description\": \"province of Canada\", \"aliases\": [\"BC\", \"B.C.\", \"Province of British Columbia\", \"CA-BC\"]}], \"triplets\": []}\\n\\n',\n",
       " 'aug_ent_num_and_base_type': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] Warden is the title of various officials.\\n[instruction] Retrieve 1 entities belonging to the following Profession types.\\n[output] {\"entities\": [{\"mention\": \"Warden\", \"title\": \"Warden\", \"type\": [\"Profession\"], \"description\": \"custodian, defender, or guardian\"}], \"triplets\": []}\\n\\n',\n",
       " 'aug_rollup_type': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] Morris County Courthouse is located on Washington Street between Court Street and Western Avenue in the town of Morristown in Morris County, New Jersey. The courthouse was built in 1827 and was added to the National Register of Historic Places on August 19, 1977, for its significance in architecture and politics/government. It was added as a contributing property of the Morristown Historic District on November 13, 1986.\\n[instruction] Please identify the entities falling under the categories mentioned in Human settlement, District.\\n[output] {\"entities\": [{\"mention\": \"Morristown\", \"title\": \"Morristown, New Jersey\", \"type\": [\"Town (New Jersey)\", \"County seat\", \"Human settlement\"], \"description\": \"town in Morris County, New Jersey, United States\", \"aliases\": [\"Morristown, NJ\", \"Morristown, New Jersey\"]}, {\"mention\": \"Morristown Historic District\", \"title\": \"Morristown District\", \"type\": [\"Historic district\", \"District\"], \"description\": \"historic district in Morris County, New Jersey\", \"aliases\": [\"Morristown Historic District\"]}], \"triplets\": [{\"head\": \"Morristown Historic District\", \"tail\": \"Morristown\", \"relations\": [\"located in the administrative territorial entity\"]}]}\\n\\n',\n",
       " 'aug_ent_num_and_rollup_type': 'This is an example for the information extraction task, which aims to extract information of entities and triplets from the given context.\\n\\n[input] The Chads House (sometimes erroneously called the Chad House), which was built by John Wyeth Jr. for John Chads (also spelled Chadds), is located in Chadds Ford, Delaware County, Pennsylvania. The house was built after 1712 and was added to the National Register of Historic Places on March 11, 1971. John Chad\\'s widow, Elizabeth, stayed in the house while it was in the line of fire during the Battle of Brandywine. The city of Chadds Ford relied on the spring ford on the property, and thus the city was named after John Chads.\\n[instruction] Please retrieve 2 entities from the following types of Human settlement, Military operation.\\n[output] {\"entities\": [{\"mention\": \"Chadds Ford\", \"title\": \"Chadds Ford, Pennsylvania\", \"type\": [\"Census-designated place\", \"Human settlement\"], \"description\": \"census-designated place in Pennsylvania, United States\"}, {\"mention\": \"Battle of Brandywine\", \"title\": \"Battle of Brandywine\", \"type\": [\"Battle\", \"Military operation\"], \"description\": \"battle of the American Revolutionary War\"}], \"triplets\": []}\\n\\n'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_shot_prompt_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"one_prompt_templates.json\", \"w\") as f:\n",
    "    json.dump(one_shot_prompt_templates, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"one_prompt.txt\", \"w\") as f:\n",
    "    f.write(one_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_prompt = \"These are examples for the information extraction task, which aims to extract information of entities and triplets from given contexts.\\n\\n\"\n",
    "for key in collect_fewshot_cases:\n",
    "    sample = collect_fewshot_cases[key]\n",
    "    few_shot_prompt += \"[input] \" + sample['inputs'] + \"\\n\"\n",
    "    few_shot_prompt += \"[instruction] \" + sample['rephrased_prompt'] + \"\\n\"\n",
    "    few_shot_prompt += \"[output] \" + sample['targets'] + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_instruction = \"\"\"\n",
    "Please provide the response in the JSON format. The response should contains entities and triplets. Each entity has its mention, title, a list of types, description, and a list of aliases. Each triplet has its head and tail mentions, and a list of relations.\n",
    "\"\"\"\n",
    "\n",
    "format_instruction = \"\"\"\n",
    "Please provide the response in the JSON format. The response should contains entities and triplets. Each entity has its mention, title, a list of types, description, and a list of aliases. Each triplet has its head and tail mentions, and a list of relations. Here is an example of the return JSON format: {\"entities\": [{\"mention\": String, \"title\": String, \"type\": List[String], \"description\": String, \"aliases\":List[String]}], \"triplets\": [{\"head\": String, \"tail\": String, \"relations\": List[String]}]}.\n",
    "\"\"\"\n",
    "\n",
    "fewshot_instruction = \"\"\"Please provide the output of this case and only return the JSON.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_history = []\n",
    "for key in collect_fewshot_cases:\n",
    "    sample = collect_fewshot_cases[key]\n",
    "    fewshot_history.extend([\n",
    "        {\"role\": \"user\", \"content\": f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + fewshot_instruction},\n",
    "        {\"role\": \"assistant\", \"content\": sample['targets']},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fewshot_prompt.txt\", \"w\") as f:\n",
    "    f.write(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneshot_history = {key: [] for key in collect_fewshot_cases}\n",
    "for key in collect_fewshot_cases:\n",
    "    sample = collect_fewshot_cases[key]\n",
    "    oneshot_history[key].extend([\n",
    "        {\"role\": \"user\", \"content\": f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + format_instruction},\n",
    "        {\"role\": \"assistant\", \"content\": sample['targets']},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"oneshot_history_format.txt\", \"w\") as f:\n",
    "    json.dump(oneshot_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"oneshot_history_prompt.txt\", \"w\") as f:\n",
    "    json.dump(oneshot_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fewshot_history_prompt.txt\", \"w\") as f:\n",
    "    json.dump(fewshot_history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"oneshot_history.txt\") as f:\n",
    "    oneshot_history = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = [json.loads(line) for line in open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_test_prompt_rephrased\").readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(eval_data)\n",
    "eval_data_sample = eval_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.74186"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_sum = 0\n",
    "for query in eval_data_sample:\n",
    "    query = few_shot_prompt + f\"[input] {query['inputs']}\\n\\n\" + f\"[instruction] {query['rephrased_prompt']}\" + query['targets']\n",
    "    length_sum += len((query + fewshot_instruction).split(\" \"))\n",
    "length_sum/1000*0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sample, case=\"oneshot_history\"):\n",
    "  sample = copy.deepcopy(sample)\n",
    "  if case == \"fewshot\":\n",
    "    query = few_shot_prompt + f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + fewshot_instruction\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "              {\"role\": \"user\", \"content\": query},\n",
    "          ]\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      message = None\n",
    "    if message:\n",
    "      message = message.replace(\"[output]\", \"\").replace(\"[Output]\", \"\").strip()\n",
    "  elif case == \"oneshot\":\n",
    "    query = one_shot_prompt_templates[sample['aug_type']] + f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + fewshot_instruction\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "              {\"role\": \"user\", \"content\": query},\n",
    "          ]\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      message = None\n",
    "    if message:\n",
    "      message = message.replace(\"[output]\", \"\").replace(\"[Output]\", \"\").strip()\n",
    "  elif case == \"oneshot_history\":\n",
    "    query = f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + fewshot_instruction\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=oneshot_history[sample['aug_type']] + [\n",
    "              {\"role\": \"user\", \"content\": query},\n",
    "          ]\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      message = None\n",
    "  elif case == \"fewshot_history\":\n",
    "    query = f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + fewshot_instruction\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=fewshot_history + [\n",
    "              {\"role\": \"user\", \"content\": query},\n",
    "          ]\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      message = None\n",
    "  elif case == \"format\":\n",
    "    query = f\"[input] {sample['inputs']}\\n[instruction] {sample['rephrased_prompt']}\\n\\n\" + format_instruction\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "              {\"role\": \"user\", \"content\": query},\n",
    "          ]\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      message = None\n",
    "\n",
    "  sample['outputs'] = message\n",
    "  return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70304871a0df405586056650727ba6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9e3040e71c1d3f32f6a9aa6781cf5413 in your message.)\n",
      "That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f57545410bf0549e1f681597a7b8a6ac in your message.)\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with Pool(64) as p:\n",
    "    pbar = tqdm(total=len(eval_data))\n",
    "    for result in p.imap_unordered(inference, eval_data):\n",
    "        results.append(result)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for each in results:\n",
    "    try:\n",
    "        message = each['outputs']\n",
    "        json.loads(message)\n",
    "    except (json.JSONDecodeError, TypeError):\n",
    "        #print(message)\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/evaluation_corpus/wiki_aug_eval/full_chatgpt_data_v4_corpus_filtered_one_shot_history_prompt_case_output.txt\", \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_s1_p = {\n",
    "    'english': '''The given sentence is \"{}\"\\n\\nWhat entity types may be included in this sentence?\\nIf not present, answer: none.\\nRespond as a list of entity types, e.g. [entity type 1, entity type 2, ......]:'''\n",
    "}\n",
    "\n",
    "ner_s2_p = {\n",
    "    'english': '''According to the given sentence, please identify the entity whose type is \"{}\".\\nIf not present, answer: none.\\nRespond in the form of a table with two columns and a header of (entity type, entity name):'''\n",
    "}\n",
    "\n",
    "re_s1_p = {\n",
    "    'english': '''The given sentence is \"{}\"\\n\\nWhat relations might be included in this given sentence?\\nIf not present, answer: none.\\nRespond as a tuple, e.g. (relation 1, relation 2, ......):''',\n",
    "}\n",
    "\n",
    "re_s2_p = {\n",
    "    'english': '''According to the given sentence, there exists two entities with the relation '{}', find the two entities and list them all by group if there are multiple groups.\\nIf not present, answer: none.\\nRespond in the form of a table with two columns and a header of ('head', 'tail'):''',\n",
    "}\n",
    "\n",
    "\n",
    "def chatbot(messages):\n",
    "    try:\n",
    "      response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "      )\n",
    "      message = response['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      message = ''\n",
    "    return message\n",
    "\n",
    "\n",
    "def chatner(sent, verbose=False):\n",
    "    mess = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    lang = \"english\"\n",
    "\n",
    "    out = []\n",
    "\n",
    "    try:\n",
    "        if verbose:\n",
    "            print('---stage1---')\n",
    "        # 构造prompt\n",
    "        s1p = ner_s1_p[lang].format(sent)\n",
    "        if verbose:\n",
    "            print(s1p)\n",
    "\n",
    "        # 请求chatgpt\n",
    "        mess.append({\"role\": \"user\", \"content\": s1p})\n",
    "        text1 = chatbot(mess)\n",
    "        mess.append({\"role\": \"assistant\", \"content\": text1})\n",
    "        if verbose:\n",
    "            print(text1)\n",
    "\n",
    "        # 正则提取结果, ner特殊\n",
    "        if lang == 'chinese':\n",
    "            res1 = re.findall(r'\\(.*?\\)', text1)\n",
    "        else:\n",
    "            res1 = re.findall(r'\\[.*?\\]', text1)\n",
    "        if verbose:\n",
    "            print(res1)\n",
    "        if res1!=[]:\n",
    "            rels = [temp[1:-1].split(',') for temp in res1]\n",
    "            rels = list(set([re.sub('[\\'\"]','', j).strip() for i in rels for j in i]))\n",
    "            #print(rels)\n",
    "        else:\n",
    "            rels = []\n",
    "        if verbose:\n",
    "            print(rels)\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(e)\n",
    "            print('ner stage 1 none out or error')\n",
    "        return ['error-stage1:' + str(e)], mess\n",
    "\n",
    "    if verbose:\n",
    "        print('---stage2')\n",
    "    try:\n",
    "        for r in rels:\n",
    "            # 构造prompt\n",
    "            s2p = ner_s2_p[lang].format(r)\n",
    "            if verbose:\n",
    "                print(s2p)\n",
    "\n",
    "            # 请求chatgpt\n",
    "            mess.append({\"role\": \"user\", \"content\": s2p})\n",
    "            text2 = chatbot(mess)\n",
    "            mess.append({\"role\": \"assistant\", \"content\": text2})\n",
    "            if verbose:\n",
    "                print(text2)\n",
    "\n",
    "            # 正则提取结果\n",
    "            res2 = re.findall(r'\\|.*?\\|.*?\\|', text2)\n",
    "            if verbose:\n",
    "                print(res2)\n",
    "\n",
    "            # 进一步处理结果\n",
    "            count=0\n",
    "            for so in res2:\n",
    "                count+=1\n",
    "                if count <=2: # 过滤表头\n",
    "                    continue\n",
    "\n",
    "                so = so[1:-1].split('|')\n",
    "                so = [re.sub('[\\'\"]','', i).strip() for i in so]\n",
    "                if len(so)==2:\n",
    "                    s, o = so\n",
    "                    #if st in s and ot in o or '---' in s and '---' in o:\n",
    "                    #    continue \n",
    "                    out.append((o, r))\n",
    "    \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(e)\n",
    "            print('ner stage 2 none out or error')\n",
    "        if out == []:\n",
    "            out.append('error-stage2:' + str(e))\n",
    "        return out, mess\n",
    "    \n",
    "\n",
    "    if out == []:\n",
    "        out.append('none-none')\n",
    "    else:\n",
    "        out = list(set(out))\n",
    "    \n",
    "    if verbose:\n",
    "        print(mess)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatre(sent, verbose=False):\n",
    "    if verbose:\n",
    "        print(\"---RE---\")\n",
    "    mess = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},] # chatgpt对话历史\n",
    "\n",
    "    lang = 'english'\n",
    "\n",
    "    out = [] # 输出列表 [(e1,r1,e2)]\n",
    "\n",
    "    try:\n",
    "        if verbose:\n",
    "            print('---stage1---')\n",
    "        # 构造prompt\n",
    "        s1p = re_s1_p[lang].format(sent)\n",
    "        if verbose:\n",
    "            print(s1p)\n",
    "\n",
    "        # 请求chatgpt\n",
    "        mess.append({\"role\": \"user\", \"content\": s1p})\n",
    "        text1 = chatbot(mess)\n",
    "        mess.append({\"role\": \"assistant\", \"content\": text1})\n",
    "        if verbose:\n",
    "            print(\"text1:\", text1)\n",
    "\n",
    "        # 正则提取结果\n",
    "        res1 = re.findall(r'\\(.*?\\)', text1)\n",
    "        if verbose:\n",
    "            print(res1)\n",
    "        if res1!=[]:\n",
    "            rels = [temp[1:-1].split(',') for temp in res1]\n",
    "            rels = list(set([re.sub('[\\'\"]','', j).strip() for i in rels for j in i]))\n",
    "            #print(rels)\n",
    "        else:\n",
    "            rels = []\n",
    "        if verbose:\n",
    "            print(rels)\n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(e)\n",
    "            print('re stage 1 none out or error')\n",
    "        return ['error-stage1:' + str(e)], mess\n",
    "\n",
    "    if verbose:\n",
    "        print('---stage2')\n",
    "    try:\n",
    "        for r in rels:\n",
    "            # 构造prompt\n",
    "            s2p = re_s2_p[lang].format(r)\n",
    "            if verbose:\n",
    "                print(s2p)\n",
    "\n",
    "            # 请求chatgpt\n",
    "            mess.append({\"role\": \"user\", \"content\": s2p})\n",
    "            text2 = chatbot(mess)\n",
    "            mess.append({\"role\": \"assistant\", \"content\": text2})\n",
    "            if verbose:\n",
    "                print(text2)\n",
    "\n",
    "            # 正则提取结果\n",
    "            res2 = re.findall(r'\\|.*?\\|.*?\\|', text2)\n",
    "            if verbose:\n",
    "                print(res2)\n",
    "\n",
    "            # 进一步处理结果\n",
    "            count=0\n",
    "            for so in res2:\n",
    "                count+=1\n",
    "                if count <=2: # 过滤表头\n",
    "                    continue\n",
    "\n",
    "                so = so[1:-1].split('|')\n",
    "                so = [re.sub('[\\'\"]','', i).strip() for i in so]\n",
    "                if len(so)==2:\n",
    "                    s, o = so\n",
    "                    #if st in s and ot in o or '---' in s and '---' in o:\n",
    "                    #    continue \n",
    "                    out.append((s, r, o))\n",
    "            #break\n",
    "    \n",
    "    except Exception as e:\n",
    "        if verbose:\n",
    "            print(e)\n",
    "            print('re stage 2 none out or error')\n",
    "        if out == []:\n",
    "            out.append('error-stage2:' + str(e))\n",
    "        return out, mess\n",
    "\n",
    "    if out == []:\n",
    "        out.append('none-none')\n",
    "    else:\n",
    "        out = list(set(out))\n",
    "    \n",
    "    if verbose:\n",
    "        print(mess)\n",
    "    # out = [('滴答', '歌手', '陈思成'), ('兰花指', '歌手', '阿里郎'), ('滴答', '歌手', '张碧晨')]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Minister of State for the Pacific and the International Environment',\n",
       "  'Position'),\n",
       " ('Minister of State for Europe and the Americas', 'Position'),\n",
       " ('Foreign, Commonwealth and Development Office (FCDO)',\n",
       "  'Government department/office'),\n",
       " ('Minister of State for Foreign Affairs', 'Position')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatner(eval_data[4]['inputs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chatner(sample):\n",
    "    sample = copy.deepcopy(sample)\n",
    "    out = chatner(sample['inputs'])\n",
    "    sample['ner_out'] = out\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/24393 [00:12<16:59:49,  2.51s/it]\n",
      "Process ForkPoolWorker-185:\n",
      "Process ForkPoolWorker-179:\n",
      "Process ForkPoolWorker-180:\n",
      "Process ForkPoolWorker-183:\n",
      "Process ForkPoolWorker-187:\n",
      "Process ForkPoolWorker-186:\n",
      "Process ForkPoolWorker-189:\n",
      "Process ForkPoolWorker-188:\n",
      "Process ForkPoolWorker-192:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/local_workspace/anaconda3/envs/transformers/lib/python3.8/site-packages/multiprocess/pool.py:851\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 851\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[1;32m    852\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mwith\u001b[39;00m Pool(\u001b[39m16\u001b[39m) \u001b[39mas\u001b[39;00m p:\n\u001b[1;32m      3\u001b[0m     pbar \u001b[39m=\u001b[39m tqdm(total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(eval_data))\n\u001b[0;32m----> 4\u001b[0m     \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m p\u001b[39m.\u001b[39mimap_unordered(run_chatner, eval_data):\n\u001b[1;32m      5\u001b[0m         results\u001b[39m.\u001b[39mappend(result)\n\u001b[1;32m      6\u001b[0m         pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/local_workspace/anaconda3/envs/transformers/lib/python3.8/site-packages/multiprocess/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 856\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    857\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m~/local_workspace/anaconda3/envs/transformers/lib/python3.8/threading.py:302\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    303\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    304\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with Pool(16) as p:\n",
    "    pbar = tqdm(total=len(eval_data))\n",
    "    for result in p.imap_unordered(run_chatner, eval_data):\n",
    "        results.append(result)\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([each['ner_out'][0] != 'none-none' for each in results])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fceb5c14fd5bb9497f9330c2eeb829ea1da1239a1871fb05da80190d45a37701"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
