{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from genre.hf_model import GENRE\n",
    "from genre.entity_linking import get_end_to_end_prefix_allowed_tokens_fn_hf as get_prefix_allowed_tokens_fn\n",
    "from genre.utils import get_entity_spans_hf as get_entity_spans\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from multiprocessing import Pool\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/harddisk/user/keminglu/pretrained_data_processed/wikipedia_with_mention_wo_title_simplified_aug_eval/corpus_filtered_test_prompt_rephrased\") as f:\n",
    "    data = [json.loads(line) for line in f.readlines()]\n",
    "data = [sample for sample in data if sample['aug_type'] == 'aug_default'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(\n",
    "        node_data,\n",
    "        batch_size=4,\n",
    "        config=\"./models/hf_e2e_entity_linking_aidayago\",\n",
    "    ):\n",
    "    num_batch = int(np.ceil(len(node_data) / batch_size))\n",
    "\n",
    "    device = torch.device(f\"cuda:4\")\n",
    "    model = GENRE.from_pretrained(config).eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    results = []\n",
    "    for i in trange(num_batch):\n",
    "        batch_begin, batch_end = i * batch_size, (i+1) * batch_size\n",
    "        batch_data = node_data[batch_begin:batch_end]\n",
    "        text_inputs = [each['inputs'] for each in batch_data]\n",
    "        outputs = get_entity_spans(\n",
    "            model,\n",
    "            text_inputs\n",
    "        )\n",
    "        assert len(batch_data) == len(outputs)\n",
    "        for k in range(len(outputs)):\n",
    "            try:\n",
    "                processed_output = [(item[3], item[2].replace(\"_\", \" \")) for item in outputs[k] if len(item) == 4]\n",
    "            except IndexError:\n",
    "                print(outputs[k])\n",
    "            batch_data[k]['outputs'] = processed_output\n",
    "        results.extend(batch_data)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [12:15<00:00, 29.42s/it]\n"
     ]
    }
   ],
   "source": [
    "results = inference(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genre_output.json\", \"w\") as f:\n",
    "    for result in results:\n",
    "        f.write(json.dumps(result) + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"genre_output.json\") as f:\n",
    "    data_0 = [json.loads(line) for line in f.readlines()]\n",
    "with open(\"genre_output_1.json\") as f:\n",
    "    data_1 = [json.loads(line) for line in f.readlines()]\n",
    "with open(\"genre_output_2.json\") as f:\n",
    "    data_2 = [json.loads(line) for line in f.readlines()]\n",
    "with open(\"genre_output_3.json\") as f:\n",
    "    data_3 = [json.loads(line) for line in f.readlines()]\n",
    "data = data_0 + data_1 + data_2 + data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {\n",
    "    \"pos_mention\": 0,\n",
    "    \"pos_mention_seen\": 0,\n",
    "    \"pos_mention_unseen\": 0,\n",
    "    \"pos_title\": 0,\n",
    "    \"pos_title_seen\": 0,\n",
    "    \"pos_title_unseen\": 0,\n",
    "    \"total\": 0,\n",
    "    \"pred_total\": 0,\n",
    "    \"total_seen\": 0,\n",
    "    \"total_unseen\": 0,\n",
    "}\n",
    "threshold = 0.99\n",
    "\n",
    "R = Rouge()\n",
    "for sample in data:\n",
    "    targets = {each['mention']: each['title'] for each in json.loads(sample['targets'])['entities']}\n",
    "    unseen_targets = {each['mention']: each['title'] for each in json.loads(sample['targets'])['entities'] if each['ood'] != 'in'}\n",
    "    seen_targets = {each['mention']: each['title'] for each in json.loads(sample['targets'])['entities'] if each['ood'] == 'in'}\n",
    "    outputs = {item[0]: item[1] for item in sample['outputs']}\n",
    "\n",
    "\n",
    "    pos_mention = 0\n",
    "    pos_title = 0\n",
    "    for key in targets:\n",
    "        if key in outputs:\n",
    "            pos_mention += 1\n",
    "            rouge = R.get_scores(outputs[key], targets[key])[0]['rouge-l']['f']\n",
    "            if rouge >= threshold:\n",
    "                pos_title += 1\n",
    "\n",
    "    pos_mention_seen = 0\n",
    "    pos_title_seen = 0\n",
    "    for key in seen_targets:\n",
    "        if key in outputs:\n",
    "            pos_mention_seen += 1\n",
    "            if outputs[key] == seen_targets[key]:\n",
    "                pos_title_seen += 1\n",
    "\n",
    "    pos_mention_unseen = 0\n",
    "    pos_title_unseen = 0\n",
    "    for key in unseen_targets:\n",
    "        if key in outputs:\n",
    "            pos_mention_unseen += 1\n",
    "            if outputs[key] == unseen_targets[key]:\n",
    "                pos_title_unseen += 1\n",
    "\n",
    "    report['pos_mention'] += pos_mention\n",
    "    report['pos_mention_seen'] += pos_mention_seen\n",
    "    report['pos_mention_unseen'] += pos_mention_unseen\n",
    "\n",
    "    report['pos_title'] += pos_title\n",
    "    report['pos_title_seen'] += pos_title_seen\n",
    "    report['pos_title_unseen'] += pos_title_unseen\n",
    "\n",
    "    report['pred_total'] += len(outputs)\n",
    "\n",
    "    report['total'] += len(targets)\n",
    "    report['total_seen'] += len(seen_targets)\n",
    "    report['total_unseen'] += len(unseen_targets)\n",
    "\n",
    "report['mention_recall'] = report['pos_mention'] / report['total']\n",
    "report['mention_precision'] = report['pos_mention'] / report['pred_total']\n",
    "report['mention_f1'] = 2 * report['mention_precision'] * report['mention_recall'] / (report['mention_precision'] + report['mention_recall'])\n",
    "\n",
    "report['title_recall'] = report['pos_title'] / report['total']\n",
    "report['title_precision'] = report['pos_title'] / report['pred_total']\n",
    "report['title_f1'] = 2 * report['title_precision'] * report['title_recall'] / (report['title_precision'] + report['title_recall'])\n",
    "\n",
    "report['seen_mention_recall'] = report['pos_mention_seen'] / report['total_seen']\n",
    "report['seen_title_recall'] = report['pos_title_seen'] / report['total_seen']\n",
    "report['unseen_mention_recall'] = report['pos_mention_unseen'] / report['total_unseen']\n",
    "report['unseen_title_recall'] = report['pos_title_unseen'] / report['total_unseen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.247637608293346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report['seen_title_recall']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
